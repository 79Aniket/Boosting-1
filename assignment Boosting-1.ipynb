{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a31e8c4-819b-448e-9a60-f49645d6e56a",
   "metadata": {},
   "source": [
    "## Q1. What is boosting in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ba0f8-116f-414a-8597-7f6116af2578",
   "metadata": {},
   "source": [
    "## Boosting in machine learning is a technique for training a collection of machine learning algorithms to work better together to increase accuracy, reduce bias and reduce variance. When the algorithms harmonize their results, they are called an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be52cb6-0a0a-4e26-89fa-18926f21cea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61b58d99-eb0b-4538-b783-85c87af25192",
   "metadata": {},
   "source": [
    "## Q2. What are the advantages and limitations of using boosting techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd4bad-3a69-4011-8907-e40dedac2b1e",
   "metadata": {},
   "source": [
    "## Advantages of boosting techniques:\n",
    "## High accuracy.\n",
    "## Robustness to overfitting.\n",
    "## Easy to implement.\n",
    "## Flexible.\n",
    "\n",
    "## Limitations of boosting techniques:\n",
    "## Computational complexity\n",
    "## Interpretability\n",
    "## Sensitivity to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d8e64-afd9-4552-ac3c-c4f1ca052fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0305001f-2f06-47dd-a7cd-f2ddb1313914",
   "metadata": {},
   "source": [
    "## Q3. Explain how boosting works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6bb2b-6f48-431a-9303-302cacbedb10",
   "metadata": {},
   "source": [
    "## Boosting works by iteratively training weak learners and combining them in a way that improves the overall accuracy of the ensemble.\n",
    "## Boosting works by focusing on the data points that are most difficult for the weak learners to classify. In each ##the  ensemble is able to classify all of the data points correctly or until a desired level of accuracy is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb4b85-a616-4b75-8c7b-73c5867ae1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8b79a20-ea9a-4441-8623-dffad52b1d90",
   "metadata": {},
   "source": [
    "## Q4. What are the different types of boosting algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c88fb-14d1-4e37-9d5f-24c5d2d37849",
   "metadata": {},
   "source": [
    "## There are many different types of boosting algorithms:\n",
    "## AdaBoost.\n",
    "## Gradient Boosting Machines .\n",
    "## CatBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830cbb7-1bfe-42c5-917b-dfbffff33ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9af4dc07-c978-474d-8ce8-ad02aa7f6cd7",
   "metadata": {},
   "source": [
    "## Q5. What are some common parameters in boosting algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab169b9-60a7-4300-8d4a-3da86e4348ca",
   "metadata": {},
   "source": [
    "## Common parameters in boosting algorithms:\n",
    "## Learning rate.\n",
    "## Number of estimators.\n",
    "## Tree depth.\n",
    "## Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257862c-be7f-473a-9d6a-578000ba1816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50a60d79-78d1-4b55-bddd-933e8134690e",
   "metadata": {},
   "source": [
    "## Q6. How do boosting algorithms combine weak learners to create a strong learner?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d98c1-353d-4705-8081-dac17c383ec7",
   "metadata": {},
   "source": [
    "## Boosting algorithms combine weak learners to create a strong learner by iteratively training weak learners on weighted versions of the training data. The weights are assigned to the data points in such a way that the subsequent weak learners are trained to focus on the data points that the previous weak learners were unable to learn correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2670d-c3bc-4479-8fda-9704e85e9d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b55e47-0235-409b-b811-539c63a4fbf7",
   "metadata": {},
   "source": [
    "## Q7. Explain the concept of AdaBoost algorithm and its working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08916f-5fad-46f7-abf6-47458276f7bd",
   "metadata": {},
   "source": [
    "## AdaBoost, short for Adaptive Boosting, is an ensemble machine learning algorithm that can be used in a wide variety of classification and regression tasks. It is a supervised learning algorithm that is used to classify data by combining multiple weak or base learners (e.g., decision trees) into a strong learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451bc78-366f-4f7a-8109-6c639bb204ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a719be67-72ea-4559-9e2b-447a116ab54d",
   "metadata": {},
   "source": [
    "## Q9. How does the AdaBoost algorithm update the weights of misclassified samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531a3fc-bd88-45cc-97aa-df35b472882d",
   "metadata": {},
   "source": [
    "## The AdaBoost algorithm updates the weights of misclassified samples by increasing the weights of the misclassified samples and decreasing the weights of the correctly classified samples. This is done so that the subsequent weak learners are trained to focus on the data points that the previous weak learners were unable to learn correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa500c03-d7e5-4145-81c1-aaa86f43d3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
